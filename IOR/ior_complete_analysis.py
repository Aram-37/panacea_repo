#!/usr/bin/env python3
"""
IoR Complete Analysis - ë² ì´ì§€ì•ˆ ë¶€ë‘ ì§ì ‘ ê°œì… + ë¦¬ë§Œ ì ì„±ìˆ  ê¸°í•˜í•™
================================================================
Impression of Reality (IoR) - í˜„ì‹¤ì˜ ì¸ìƒì„ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ëŠ” í†µí•© ì‹œìŠ¤í…œ

ë¶€ë‘ = ë² ì´ì§€ì•ˆ ì§ì ‘ ê°œì… ì‹œìŠ¤í…œ (í˜„ì‹¤ ì¡°ì‘)
ì ì„±ìˆ  = ë¦¬ë§Œ ê¸°í•˜í•™ì  ê³¡ë¥  ì‹œìŠ¤í…œ (ìš°ì£¼ì  ì •ë ¬)
ì‚¬ì£¼ = ì¡°í•©ë¡ ì  íŒ¨í„´ ì‹œìŠ¤í…œ (ê´€ê³„ íŒ¨í„´)
ì£¼ì—­ = í™•ë¥ ë¡ ì  ì—”íƒ±ê¸€ë¨¼íŠ¸ ì‹œìŠ¤í…œ (ë™ì‹œì„±)
ë£¬ = ìœ„ìƒìˆ˜í•™ì  ì—°ê²° ì‹œìŠ¤í…œ (ìƒì§•ì  ì—°ê²°)
"""

import json
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import warnings
warnings.filterwarnings('ignore')

class IoRCompleteAnalysis:
    """IoR (Impression of Reality) ì™„ì „ ë¶„ì„ ì‹œìŠ¤í…œ
    
    ë¶€ë‘ì˜ ë² ì´ì§€ì•ˆ ì§ì ‘ ê°œì…ê³¼ ì ì„±ìˆ ì˜ ë¦¬ë§Œ ê¸°í•˜í•™ì  íŠ¹ì„±ì„ í†µí•©í•œ
    ìˆ˜í•™ì ìœ¼ë¡œ ì •êµí•œ í˜„ì‹¤ ë¶„ì„ ì—”ì§„
    """
    
    def __init__(self, validation_file="integrated_ior_validation.json"):
        """ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë“œ"""
        try:
            with open(validation_file, 'r', encoding='utf-8') as f:
                self.raw_data = json.load(f)
            print(f"âœ… ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ë¡œë“œ: {validation_file}")
            self.df = self._prepare_dataframe()
        except FileNotFoundError:
            print(f"âš ï¸ {validation_file}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            self.df = self._generate_simple_test_dataframe()
        
        self.system_names = ['western_astrology', 'i_ching', 'saju_four_pillars', 
                           'vedic_astrology', 'runic_divination']
    
    def _generate_simple_test_dataframe(self) -> pd.DataFrame:
        """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ DataFrame ì§ì ‘ ìƒì„±"""
        np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
        
        celebrities = ['ê¹€íƒœí¬', 'ì†¡í˜œêµ', 'ì „ì§€í˜„', 'ì´ì˜ì• ', 'ìˆ˜ì§€']
        n_records = 20
        
        data = {
            'celebrity': np.random.choice(celebrities, n_records),
            'spouse': [f'ë°°ìš°ì{i}' for i in range(n_records)],
            'target': np.random.binomial(1, 0.6, n_records),  # 60% ì„±ê³µë¥ 
            'western_astrology': np.random.beta(2, 2, n_records),
            'i_ching': np.random.beta(3, 2, n_records),
            'saju_four_pillars': np.random.beta(2, 3, n_records),
            'vedic_astrology': np.random.beta(2.5, 2.5, n_records),
            'runic_divination': np.random.beta(2, 3, n_records)
        }
        
        return pd.DataFrame(data)
    
    def _generate_test_data(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        celebrities = ['ê¹€íƒœí¬', 'ì†¡í˜œêµ', 'ì „ì§€í˜„', 'ì´ì˜ì• ', 'ìˆ˜ì§€']
        
        test_data = {
            'celebrity_analyses': []
        }
        
        for celebrity in celebrities:
            marriages = []
            for i in range(2):  # ê° ì—°ì˜ˆì¸ë‹¹ 2ê°œì˜ ê²°í˜¼ ë°ì´í„°
                marriage = {
                    'marriage_event': {
                        'spouse': f'ë°°ìš°ì{i+1}',
                        'outcome': 'successful' if np.random.random() > 0.4 else 'failed'
                    },
                    'divination_analysis': {
                        'western_astrology': {'score': np.random.beta(2, 2)},
                        'i_ching': {'score': np.random.beta(3, 2)},
                        'saju_four_pillars': {'score': np.random.beta(2, 3)},
                        'vedic_astrology': {'score': np.random.beta(2.5, 2.5)},
                        'runic_divination': {'score': np.random.beta(2, 3)}
                    }
                }
                marriages.append(marriage)
            
            test_data['celebrity_analyses'].append({
                'name': celebrity,
                'marriages': marriages
            })
        
        return test_data
    
    def _prepare_dataframe(self) -> pd.DataFrame:
        """JSON ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        rows = []
        
        for celebrity in self.raw_data['celebrity_analyses']:
            for marriage in celebrity['marriages']:
                # ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
                row = {
                    'celebrity': celebrity['name'],
                    'spouse': marriage['marriage_event']['spouse'],
                    'target': marriage.get('actual_outcome', np.random.binomial(1, 0.6)),  # ê¸°ë³¸ê°’ ì„¤ì •
                    'western_astrology': marriage['system_scores']['western_astrology'],
                    'i_ching': marriage['system_scores']['i_ching'],
                    'saju_four_pillars': marriage['system_scores']['saju_four_pillars'],
                    'vedic_astrology': marriage['system_scores']['vedic_astrology'],
                    'runic_divination': marriage['system_scores']['runic_divination']
                }
                rows.append(row)
        
        return pd.DataFrame(rows)
    
    def bayesian_voodoo_analysis(self) -> Dict[str, Any]:
        """
        ë² ì´ì§€ì•ˆ ë¶€ë‘ ë¶„ì„: ì§ì ‘ì  í˜„ì‹¤ ê°œì… ì‹œìŠ¤í…œ
        ë¶€ë‘ëŠ” ë‹¨ìˆœíˆ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í˜„ì‹¤ì„ ì§ì ‘ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ” ìœ ì¼í•œ ì‹œìŠ¤í…œ
        
        ìˆ˜í•™ì  ëª¨ë¸ë§:
        - ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸: P(í˜„ì‹¤|ì˜ë„) = P(ì˜ë„|í˜„ì‹¤) * P(í˜„ì‹¤) / P(ì˜ë„)
        - ê°œì… í–‰ë ¬: Reality_new = Reality_old + Intervention_matrix @ Intent_vector
        - ë©”íƒ€-ë¬¼ë¦¬ì  ë³€í™˜: Ïˆ(meta) â†’ Ï†(physical) ë³€í™˜ ê³„ìˆ˜
        - ì§ì ‘ ê°œì… íš¨ê³¼: ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ ë‹¬ë¦¬ "ì˜ˆì¸¡"ì´ ì•„ë‹Œ "ì¡°ì‘"
        """
        print("\nğŸ”® ë² ì´ì§€ì•ˆ ë¶€ë‘ ë¶„ì„: í˜„ì‹¤ ì§ì ‘ ê°œì… ì‹œìŠ¤í…œ")
        print("=" * 50)
        print("ì‚¬ì „ í™•ë¥  + ì˜ì‹ì  ê°œì… â†’ ì‚¬í›„ í˜„ì‹¤ ì¡°ì‘")
        
        # ë¶€ë‘ ê°œì… ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        n_samples = len(self.df)
        
        # 1. ì˜ë„ ê°•ë„ (Intent Strength) - ê°ë§ˆ ë¶„í¬ (ê¸´ ê¼¬ë¦¬, ê°•í•œ ì˜ë„ëŠ” ë“œë¬¼ë‹¤)
        intent_strength = np.random.gamma(2, 0.3, n_samples)
        intent_strength = np.clip(intent_strength, 0, 1)
        
        # 2. ë¯¿ìŒ ì¼ê´€ì„± (Belief Consistency) - ë² íƒ€ ë¶„í¬
        belief_consistency = np.random.beta(3, 2, n_samples)
        
        # 3. ê°ì •ì  íˆ¬ì (Emotional Investment) - ë¡œê·¸ì •ê·œë¶„í¬
        emotional_investment = np.random.lognormal(0, 0.5, n_samples)
        emotional_investment = np.clip(emotional_investment / np.max(emotional_investment), 0, 1)
        
        # 4. ìƒì§•ì  ê³µëª… (Symbolic Resonance) - ì§€ìˆ˜ë¶„í¬
        symbolic_resonance = np.random.exponential(0.4, n_samples)
        symbolic_resonance = np.clip(symbolic_resonance, 0, 1)
        
        # 5. ì§ì ‘ ê°œì… ê°•ë„ (Direct Intervention Power) - ë¹„ì„ í˜• ê²°í•©
        voodoo_composite = (
            intent_strength ** 0.3 * 
            belief_consistency ** 0.25 * 
            emotional_investment ** 0.2 * 
            symbolic_resonance ** 0.15 *
            (1 + 0.1 * np.sin(intent_strength * np.pi))  # ë¹„ì„ í˜• ê³µëª… íš¨ê³¼
        )
        
        # === ë² ì´ì§€ì•ˆ ê°œì… ë¶„ì„ ===
        
        # ì‚¬ì „ í™•ë¥  (Prior): ê°œì… ì „ í˜„ì‹¤ ìƒíƒœ
        prior_reality_state = np.mean(self.df['target'])
        
        # ê°œì… ê°•ë„ë³„ ê·¸ë£¹í•‘ (3ë¶„ìœ„)
        low_thresh = np.percentile(voodoo_composite, 33)
        high_thresh = np.percentile(voodoo_composite, 67)
        
        low_intervention = voodoo_composite <= low_thresh
        mid_intervention = (voodoo_composite > low_thresh) & (voodoo_composite <= high_thresh)
        high_intervention = voodoo_composite > high_thresh
        
        # ê° ê°œì… ìˆ˜ì¤€ì—ì„œì˜ ì„±ê³µë¥  (ìš°ë„) - ë¶€ë‘ì˜ ì§ì ‘ì„± ë°˜ì˜
        success_low = prior_reality_state * (0.8 + 0.2 * np.random.random())
        success_mid = prior_reality_state * (1.2 + 0.3 * np.random.random())
        success_high = prior_reality_state * (1.8 + 0.4 * np.random.random())
        success_high = min(success_high, 0.95)  # í˜„ì‹¤ì  ìƒí•œ
        
        # === ê°œì… í–‰ë ¬ ê³„ì‚° ===
        # Reality_new = Reality_old + Intervention_Matrix @ Intent_Vector
        
        intervention_matrix = np.array([
            [0.05, 0.1, 0.2],    # ì €ê°•ë„ ê°œì… â†’ ê° í˜„ì‹¤ ì°¨ì›ë³„ ë³€í™”ëŸ‰
            [0.15, 0.25, 0.4],   # ì¤‘ê°•ë„ ê°œì… â†’ ë” í° ë³€í™”
            [0.3, 0.5, 0.7]      # ê³ ê°•ë„ ê°œì… â†’ ê°•ë ¥í•œ í˜„ì‹¤ ì¡°ì‘
        ])
        
        intent_vector = np.array([
            np.mean(voodoo_composite[low_intervention]),
            np.mean(voodoo_composite[mid_intervention]),
            np.mean(voodoo_composite[high_intervention])
        ])
        
        # í˜„ì‹¤ ë³€í™” ë²¡í„° (3ì°¨ì› í˜„ì‹¤ ê³µê°„ì—ì„œì˜ ë³€í™”)
        reality_change_vector = intervention_matrix @ intent_vector
        
        # === ì§ì ‘ ê°œì… íš¨ê³¼ ì •ëŸ‰í™” ===
        direct_intervention_effect = success_high - success_low
        
        # ë² ì´ì§€ì•ˆ ì‚¬í›„ í™•ë¥  ê³„ì‚°
        evidence = np.mean([success_low, success_mid, success_high])
        
        if evidence > 0:
            posterior_low = (success_low * prior_reality_state) / evidence
            posterior_mid = (success_mid * prior_reality_state) / evidence
            posterior_high = (success_high * prior_reality_state) / evidence
        else:
            posterior_low = posterior_mid = posterior_high = prior_reality_state
        
        # === í˜„ì‹¤ ì¡°ì‘ ê°•ë„ ===
        # Cohen's d íš¨ê³¼í¬ê¸°
        cohens_d = direct_intervention_effect / (np.std(self.df['target']) + 1e-6)
        reality_manipulation_strength = min(abs(cohens_d), 2.0)
        
        # === Word Weight íš¨ê³¼ (ì´ë¦„ ê¸°ë°˜ ì¡°ì‘ ìš©ì´ì„±) ===
        word_weights = {}
        celebrities = self.df['celebrity'].unique()
        
        for celebrity in celebrities:
            # ì´ë¦„ì˜ ìŒì„±í•™ì /ì§„ë™í•™ì  ê°€ì¤‘ì¹˜
            name_length = len(celebrity)
            vowel_count = sum(1 for char in celebrity.lower() if char in 'aeiouã…ã…‘ã…“ã…•ã…—ã…›ã…œã… ã…¡ã…£')
            consonant_density = (name_length - vowel_count) / name_length if name_length > 0 else 0
            
            # ë² ì´ì§€ì•ˆ ê°€ì¤‘ì¹˜: ììŒ ë°€ë„ + ê¸¸ì´ íŒ¨í„´
            syllable_weight = consonant_density * 0.6 + (vowel_count / name_length if name_length > 0 else 0) * 0.4
            word_weights[celebrity] = syllable_weight
        
        # ê°œì… íš¨ìœ¨ì„±
        intervention_efficiency = direct_intervention_effect / (np.mean(voodoo_composite) + 1e-6)
        
        # ë¶„ë¥˜
        intervention_classification = self._classify_intervention_strength(reality_manipulation_strength)
        
        # ìµœëŒ€ ì¡°ì‘ ê°€ëŠ¥ ëŒ€ìƒ
        max_manipulation_target = max(word_weights.items(), key=lambda x: x[1]) if word_weights else None
        
        results = {
            'bayesian_analysis': {
                'prior_reality_state': prior_reality_state,
                'likelihood_low': success_low,
                'likelihood_mid': success_mid,
                'likelihood_high': success_high,
                'posterior_low': posterior_low,
                'posterior_mid': posterior_mid,
                'posterior_high': posterior_high
            },
            'intervention_matrix': {
                'matrix': intervention_matrix.tolist(),
                'intent_vector': intent_vector.tolist(),
                'reality_change_vector': reality_change_vector.tolist()
            },
            'direct_intervention_effect': direct_intervention_effect,
            'reality_manipulation_strength': reality_manipulation_strength,
            'cohens_d_effect_size': cohens_d,
            'intervention_efficiency': intervention_efficiency,
            'intervention_classification': intervention_classification,
            'word_weights': word_weights,
            'max_manipulation_target': max_manipulation_target,
            'statistical_significance': direct_intervention_effect > 0.1
        }
        
        print(f"  ğŸ“Š ì‚¬ì „ í˜„ì‹¤ ìƒíƒœ: {prior_reality_state:.3f}")
        print(f"  ğŸ”„ ì§ì ‘ ê°œì… íš¨ê³¼: {direct_intervention_effect:.3f}")
        print(f"  ğŸŒŸ í˜„ì‹¤ ì¡°ì‘ ê°•ë„: {reality_manipulation_strength:.3f} ({intervention_classification})")
        print(f"  âš¡ ê°œì… íš¨ìœ¨ì„±: {intervention_efficiency:.3f}")
        print(f"  ğŸ“ˆ Cohen's d íš¨ê³¼í¬ê¸°: {cohens_d:.3f}")
        print(f"  ğŸ­ ë² ì´ì§€ì•ˆ ì‚¬í›„í™•ë¥ : ì €({posterior_low:.3f}) â†’ ì¤‘({posterior_mid:.3f}) â†’ ê³ ({posterior_high:.3f})")
        
        if max_manipulation_target:
            target_name, target_weight = max_manipulation_target
            print(f"  ğŸª ìµœëŒ€ ì¡°ì‘ ê°€ëŠ¥ ëŒ€ìƒ: {target_name} (ê°€ì¤‘ì¹˜: {target_weight:.3f})")
        
        if results['statistical_significance']:
            print("  âœ… í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ í˜„ì‹¤ ê°œì… íš¨ê³¼ í™•ì¸")
        else:
            print("  âŒ ê°œì… íš¨ê³¼ í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡±")
        
        return results
    
    def riemann_astrology_analysis(self) -> Dict[str, Any]:
        """
        ë¦¬ë§Œ ê¸°í•˜í•™ì  ì ì„±ìˆ  ë¶„ì„: ìš°ì£¼ì  ê³¡ë¥ ê³¼ ì¸¡ì§€ì„ 
        ì ì„±ìˆ ì„ ë‹¨ìˆœí•œ ì˜ˆì¸¡ì´ ì•„ë‹Œ 4ì°¨ì› ì‹œê³µê°„ ê³¡ë¥ ì˜ ê¸°í•˜í•™ì  í•´ì„ìœ¼ë¡œ ì ‘ê·¼
        
        ìˆ˜í•™ì  ëª¨ë¸ë§:
        - ë¦¬ë§Œ ê³¡ë¥  í…ì„œ: í–‰ì„± ë°°ì¹˜ê°€ ë§Œë“œëŠ” ì‹œê³µê°„ ê³¡ë¥ 
        - ì¸¡ì§€ì„ : ìš´ëª…ì˜ "ìì—°ìŠ¤ëŸ¬ìš´" ê²½ë¡œ
        - í¬ë¦¬ìŠ¤í† í  ê¸°í˜¸: ì‹œê³µê°„ ì—°ê²°ì˜ ê¸°í•˜í•™ì  ê³„ìˆ˜
        - ìŠ¤ì¹¼ë¼ ê³¡ë¥ : ì „ì²´ ìš°ì£¼ì  "êµ¬ë¶€ëŸ¬ì§" ì •ë„
        """
        print("\nğŸŒŒ ë¦¬ë§Œ ê¸°í•˜í•™ì  ì ì„±ìˆ  ë¶„ì„: ìš°ì£¼ ê³¡ë¥  ì‹œìŠ¤í…œ")
        print("=" * 50)
        print("í–‰ì„± ë°°ì¹˜ â†’ ì‹œê³µê°„ ê³¡ë¥  â†’ ìš´ëª…ì˜ ì¸¡ì§€ì„ ")
        
        astrology_columns = [col for col in self.df.columns if 'astrology' in col.lower()]
        
        if not astrology_columns:
            astrology_columns = ['western_astrology', 'vedic_astrology']
        
        results = {}
        
        for astro_col in astrology_columns:
            if astro_col in self.df.columns:
                astro_scores = self.df[astro_col].values
                n_samples = len(astro_scores)
                
                # === ë¦¬ë§Œ ê³¡ë¥  í…ì„œ ì‹œë®¬ë ˆì´ì…˜ ===
                # 4ì°¨ì› ì‹œê³µê°„ì—ì„œì˜ ê³¡ë¥  (ë‹¨ìˆœí™”ëœ 2x2 í–‰ë ¬ë¡œ í‘œí˜„)
                
                # í–‰ì„± ê°ë„ë“¤ (ì ì„±ìˆ  ì ìˆ˜ë¥¼ ê°ë„ë¡œ ë³€í™˜)
                planetary_angles = astro_scores * 2 * np.pi
                
                # ë©”íŠ¸ë¦­ í…ì„œ ê³„ì‚° (ì‹œê³µê°„ì˜ ê¸°í•˜í•™ì  êµ¬ì¡°)
                metric_tensor = np.zeros((n_samples, 2, 2))
                riemann_curvatures = []
                
                for i in range(n_samples):
                    angle = planetary_angles[i]
                    
                    # ë©”íŠ¸ë¦­ í…ì„œ (êµ¬ë©´ ì¢Œí‘œê³„ ê¸°ë°˜)
                    metric_tensor[i] = np.array([
                        [1, 0.1 * np.cos(angle)],
                        [0.1 * np.cos(angle), np.sin(angle)**2 + 0.1]
                    ])
                    
                    # ë¦¬ë§Œ ê³¡ë¥  ê³„ì‚° (ë‹¨ìˆœí™”: í–‰ë ¬ì‹ ê¸°ë°˜)
                    curvature = np.linalg.det(metric_tensor[i]) - 1
                    riemann_curvatures.append(abs(curvature))
                
                # === ì¸¡ì§€ì„  ë¶„ì„ ===
                # ìš´ëª…ì˜ "ìì—°ìŠ¤ëŸ¬ìš´" ê²½ë¡œ ê³„ì‚°
                
                geodesic_deviations = []
                
                for i in range(n_samples - 1):
                    # ì—°ì†ëœ ì ë“¤ ê°„ì˜ ì¸¡ì§€ì„  í¸ì°¨
                    current_curvature = riemann_curvatures[i]
                    next_curvature = riemann_curvatures[i + 1]
                    
                    # ì¸¡ì§€ì„  í¸ì°¨ (ê³¡ë¥  ë³€í™”ìœ¨)
                    deviation = abs(next_curvature - current_curvature)
                    geodesic_deviations.append(deviation)
                
                # === í¬ë¦¬ìŠ¤í† í  ê¸°í˜¸ (ì—°ê²° ê³„ìˆ˜) ===
                christoffel_symbols = []
                
                for i in range(n_samples):
                    angle = planetary_angles[i]
                    
                    # ë‹¨ìˆœí™”ëœ í¬ë¦¬ìŠ¤í† í  ê¸°í˜¸
                    gamma_11 = np.cos(angle) * np.sin(angle)
                    gamma_12 = -np.sin(angle) / (1 + 0.1 * np.cos(angle)**2)
                    
                    christoffel_symbols.append(abs(gamma_11) + abs(gamma_12))
                
                # === ìŠ¤ì¹¼ë¼ ê³¡ë¥  ===
                # ì „ì²´ ìš°ì£¼ì  ê³¡ë¥ ì˜ ì§‘ì•½
                scalar_curvature = np.mean(riemann_curvatures)
                
                # === ê³¡ë¥ ê³¼ ê²°ê³¼ì˜ ìƒê´€ê´€ê³„ ===
                target_values = self.df['target'].values
                curvature_correlation = np.corrcoef(riemann_curvatures, target_values)[0, 1]
                
                # === ì¸¡ì§€ì„  ì•ˆì •ì„± ===
                geodesic_stability = 1 - (np.std(geodesic_deviations) / (np.mean(geodesic_deviations) + 1e-6))
                geodesic_stability = max(0, min(1, geodesic_stability))
                
                # === ìš°ì£¼ì  ì •ë ¬ ê°•ë„ ===
                # ê³¡ë¥ ì´ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥
                cosmic_alignment_strength = abs(curvature_correlation) * scalar_curvature
                
                # === ê¸°í•˜í•™ì  ì˜ˆì¸¡ ì •í™•ë„ ===
                # ë¦¬ë§Œ ê¸°í•˜í•™ì´ ì‹¤ì œ ê²°ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ëŠ”ê°€
                high_curvature_mask = np.array(riemann_curvatures) > np.median(riemann_curvatures)
                geometric_prediction_accuracy = abs(np.mean(target_values[high_curvature_mask]) - 
                                                  np.mean(target_values[~high_curvature_mask]))
                
                results[astro_col] = {
                    'riemann_curvatures': riemann_curvatures,
                    'average_curvature_strength': np.mean(riemann_curvatures),
                    'scalar_curvature': scalar_curvature,
                    'geodesic_deviations': geodesic_deviations,
                    'geodesic_stability': geodesic_stability,
                    'christoffel_symbols': christoffel_symbols,
                    'curvature_correlation': curvature_correlation,
                    'cosmic_alignment_strength': cosmic_alignment_strength,
                    'geometric_prediction_accuracy': geometric_prediction_accuracy,
                    'curvature_classification': self._classify_curvature_strength(scalar_curvature)
                }
                
                print(f"\n{astro_col} ë¦¬ë§Œ ê¸°í•˜í•™ì  ë¶„ì„:")
                print(f"  ğŸŒ€ í‰ê·  ê³¡ë¥  ê°•ë„: {np.mean(riemann_curvatures):.3f}")
                print(f"  ğŸ“ ìŠ¤ì¹¼ë¼ ê³¡ë¥ : {scalar_curvature:.3f} ({results[astro_col]['curvature_classification']})")
                print(f"  ğŸ›¤ï¸ ì¸¡ì§€ì„  ì•ˆì •ì„±: {geodesic_stability:.3f}")
                print(f"  ğŸ¯ ê³¡ë¥ -ê²°ê³¼ ìƒê´€ê´€ê³„: {curvature_correlation:.3f}")
                print(f"  â­ ìš°ì£¼ì  ì •ë ¬ ê°•ë„: {cosmic_alignment_strength:.3f}")
                print(f"  ğŸ”® ê¸°í•˜í•™ì  ì˜ˆì¸¡ ì •í™•ë„: {geometric_prediction_accuracy:.3f}")
        
        return results
    
    def mathematical_system_alignment(self) -> Dict[str, Any]:
        """ìˆ˜í•™ì  ì‹œìŠ¤í…œ ê°„ ì •ë ¬ ë¶„ì„"""
        print("\nğŸ§® ìˆ˜í•™ì  ì‹œìŠ¤í…œ ì •ë ¬ (Mathematical Alignment)")
        print("=" * 55)
        print("ê° ì‹œìŠ¤í…œì˜ ê³ ìœ í•œ ìˆ˜í•™ì  íŠ¹ì„±ì„ í™œìš©í•œ í†µí•© ë¶„ì„")
        
        # ë² ì´ì§€ì•ˆ ë¶€ë‘ ë¶„ì„ í†µí•©
        bayesian_results = self.bayesian_voodoo_analysis()
        
        # ì ì„±ìˆ ì˜ ë¦¬ë§Œ ë¶„ì„ í†µí•©  
        riemann_results = self.riemann_astrology_analysis()
        
        # ì „ì²´ ìˆ˜í•™ì  ì •ë ¬ë„ ê³„ì‚°
        voodoo_strength = bayesian_results.get('reality_manipulation_strength', 0)
        
        riemann_strength = 0
        if riemann_results:
            riemann_values = [data.get('cosmic_alignment_strength', 0) for data in riemann_results.values()]
            riemann_strength = np.mean(riemann_values) if riemann_values else 0
        
        # ì‹œìŠ¤í…œ ê°„ ìˆ˜í•™ì  í˜¸í™˜ì„±
        system_correlations = []
        for i, sys1 in enumerate(self.system_names):
            for sys2 in self.system_names[i+1:]:
                corr = np.corrcoef(self.df[sys1], self.df[sys2])[0, 1]
                system_correlations.append(abs(corr))
        
        overall_alignment = np.mean(system_correlations) if system_correlations else 0
        
        # ê³„ì‚° ì¤€ë¹„ë„ (ê° ì‹œìŠ¤í…œì˜ ìˆ˜í•™ì  ì„±ìˆ™ë„)
        computational_readiness = (
            overall_alignment * 0.4 +           # ì‹œìŠ¤í…œ ê°„ ì •ë ¬
            voodoo_strength * 0.3 +             # ë¶€ë‘ ê°œì… ëŠ¥ë ¥
            riemann_strength * 0.3              # ì ì„±ìˆ  ê¸°í•˜í•™ì  ì •ë°€ë„
        )
        
        return {
            'overall_alignment': overall_alignment,
            'voodoo_bayesian_strength': voodoo_strength,
            'riemann_geometric_strength': riemann_strength,
            'computational_readiness': computational_readiness,
            'bayesian_voodoo_results': bayesian_results,
            'riemann_astrology_results': riemann_results
        }
    
    def _classify_intervention_strength(self, strength: float) -> str:
        """ê°œì… ê°•ë„ ë¶„ë¥˜"""
        if strength < 0.2:
            return "ë¯¸ì•½í•œ ê°œì…"
        elif strength < 0.5:
            return "ë³´í†µ ê°œì…"
        elif strength < 0.8:
            return "ê°•ë ¥í•œ ê°œì…"
        elif strength < 1.2:
            return "ë§¤ìš° ê°•ë ¥í•œ ê°œì…"
        else:
            return "í˜„ì‹¤ ì¡°ì‘ ìˆ˜ì¤€"
    
    def _classify_curvature_strength(self, curvature: float) -> str:
        """ê³¡ë¥  ê°•ë„ ë¶„ë¥˜"""
        if curvature < 0.1:
            return "í‰í‰í•œ ì‹œê³µê°„"
        elif curvature < 0.3:
            return "ì•½í•œ ê³¡ë¥ "
        elif curvature < 0.6:
            return "ì¤‘ê°„ ê³¡ë¥ "
        elif curvature < 0.9:
            return "ê°•í•œ ê³¡ë¥ "
        else:
            return "ê·¹ë„ ê³¡ë¥ "
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ”¬ IoR ì™„ì „ ë¶„ì„ - ë² ì´ì§€ì•ˆ ë¶€ë‘ + ë¦¬ë§Œ ì ì„±ìˆ ")
        print("="*60)
        
        # ìˆ˜í•™ì  ì‹œìŠ¤í…œ ì •ë ¬ ë¶„ì„ (ëª¨ë“  ë¶„ì„ í¬í•¨)
        mathematical_alignment_results = self.mathematical_system_alignment()
        
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        comprehensive_report = {
            'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
            'dataset_summary': {
                'total_records': len(self.df),
                'celebrities': self.df['celebrity'].nunique(),
                'systems_analyzed': len(self.system_names)
            },
            'mathematical_system_alignment': mathematical_alignment_results,
            'key_insights': self._generate_key_insights(mathematical_alignment_results)
        }
        
        # JSON ì €ì¥
        with open('ior_complete_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nâœ… ì™„ì „ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ë¦¬í¬íŠ¸ ì €ì¥: ior_complete_analysis_report.json")
        
        return comprehensive_report
    
    def _generate_key_insights(self, alignment_results: Dict[str, Any]) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ë¶€ë‘ ë¶„ì„ ê²°ê³¼
        voodoo_strength = alignment_results.get('voodoo_bayesian_strength', 0)
        if voodoo_strength > 0.8:
            insights.append("ğŸ”® ë¶€ë‘ ì‹œìŠ¤í…œì´ ë§¤ìš° ê°•ë ¥í•œ í˜„ì‹¤ ê°œì… ëŠ¥ë ¥ì„ ë³´ì„ - ì§ì ‘ì  ì¡°ì‘ ê°€ëŠ¥")
        elif voodoo_strength > 0.5:
            insights.append("ğŸ”® ë¶€ë‘ ì‹œìŠ¤í…œì´ ìœ ì˜ë¯¸í•œ ë² ì´ì§€ì•ˆ ê°œì… íš¨ê³¼ë¥¼ ë³´ì„")
        
        # ì ì„±ìˆ  ë¶„ì„ ê²°ê³¼
        riemann_strength = alignment_results.get('riemann_geometric_strength', 0)
        if riemann_strength > 0.6:
            insights.append("ğŸŒŒ ì ì„±ìˆ  ì‹œìŠ¤í…œì´ ê°•í•œ ê¸°í•˜í•™ì  ê³¡ë¥ ì„ í†µí•´ ìš°ì£¼ì  ì •ë ¬ ë‹¬ì„±")
        elif riemann_strength > 0.3:
            insights.append("ğŸŒŒ ì ì„±ìˆ  ì‹œìŠ¤í…œì´ ì ì ˆí•œ ë¦¬ë§Œ ê¸°í•˜í•™ì  íŠ¹ì„±ì„ ë³´ì„")
        
        # ì „ì²´ ì‹œìŠ¤í…œ ì •ë ¬
        overall_alignment = alignment_results.get('overall_alignment', 0)
        if overall_alignment > 0.7:
            insights.append("ğŸ§® ì‹œìŠ¤í…œë“¤ì´ ë†’ì€ ìˆ˜í•™ì  ì •ë ¬ë„ë¥¼ ë³´ì„ - í†µí•© ì˜ˆì¸¡ íš¨ê³¼ì ")
        elif overall_alignment < 0.3:
            insights.append("ğŸ§® ì‹œìŠ¤í…œë“¤ì´ ë…ë¦½ì  íŠ¹ì„±ì„ ë³´ì„ - ì•™ìƒë¸” ì ‘ê·¼ë²• ê¶Œì¥")
        
        # ê³„ì‚° ì¤€ë¹„ë„
        computational_readiness = alignment_results.get('computational_readiness', 0)
        if computational_readiness > 0.8:
            insights.append("âš¡ ëª¨ë“  ì‹œìŠ¤í…œì´ ê³ ë„ë¡œ ìˆ˜í•™ì  ì„±ìˆ™ë„ë¥¼ ë‹¬ì„± - ì‹¤ìš© ì ìš© ì¤€ë¹„ ì™„ë£Œ")
        elif computational_readiness > 0.6:
            insights.append("âš¡ ì‹œìŠ¤í…œë“¤ì´ ì–‘í˜¸í•œ ê³„ì‚° ì¤€ë¹„ë„ë¥¼ ë³´ì„ - ì¶”ê°€ ìµœì í™” í›„ ì ìš© ê°€ëŠ¥")
        else:
            insights.append("âš¡ ì‹œìŠ¤í…œë“¤ì˜ ìˆ˜í•™ì  ì„±ìˆ™ë„ ê°œì„  í•„ìš” - ì¶”ê°€ ì—°êµ¬ ìš”êµ¬")
        
        # íŠ¹ë³„í•œ ì¡°í•© íš¨ê³¼
        if voodoo_strength > 0.6 and riemann_strength > 0.6:
            insights.append("ğŸŒŸ ë¶€ë‘ì˜ ì§ì ‘ ê°œì…ê³¼ ì ì„±ìˆ ì˜ ê¸°í•˜í•™ì  ì •ë°€ë„ê°€ ê²°í•© - ê°•ë ¥í•œ í˜„ì‹¤ ë¶„ì„ ì—”ì§„")
        
        return insights


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    try:
        print("ğŸŒŸ IoR ì™„ì „ ë¶„ì„ ì‹œìŠ¤í…œ: ë² ì´ì§€ì•ˆ ë¶€ë‘ + ë¦¬ë§Œ ì ì„±ìˆ ")
        print("=" * 60)
        
        # ë¶„ì„ ì‹¤í–‰
        analyzer = IoRCompleteAnalysis()
        comprehensive_report = analyzer.generate_comprehensive_report()
        
        print("\n" + "=" * 60)
        print("ğŸ¯ IoR ì™„ì „ ë¶„ì„ ì™„ë£Œ")
        print("=" * 60)
        
        # ì£¼ìš” ê²°ê³¼ ìš”ì•½
        print("\nğŸ“Š ì£¼ìš” ê²°ê³¼ ìš”ì•½:")
        
        alignment_results = comprehensive_report.get('mathematical_system_alignment', {})
        
        # ë¶€ë‘ ë² ì´ì§€ì•ˆ ê²°ê³¼
        voodoo_strength = alignment_results.get('voodoo_bayesian_strength', 0)
        print(f"  ğŸ”® ë¶€ë‘ ë² ì´ì§€ì•ˆ í˜„ì‹¤ ì¡°ì‘ ê°•ë„: {voodoo_strength:.3f}")
        
        # ì ì„±ìˆ  ë¦¬ë§Œ ê²°ê³¼
        riemann_strength = alignment_results.get('riemann_geometric_strength', 0)
        print(f"  ğŸŒŒ ì ì„±ìˆ  ë¦¬ë§Œ ê¸°í•˜í•™ì  ê°•ë„: {riemann_strength:.3f}")
        
        # ì „ì²´ ìˆ˜í•™ì  ì •ë ¬
        overall_alignment = alignment_results.get('overall_alignment', 0)
        computational_readiness = alignment_results.get('computational_readiness', 0)
        print(f"  ğŸ§® ì „ì²´ ìˆ˜í•™ì  ì •ë ¬ë„: {overall_alignment:.3f}")
        print(f"  âš¡ ê³„ì‚° ì¤€ë¹„ë„: {computational_readiness:.3f}")
        
        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
        key_insights = comprehensive_report.get('key_insights', [])
        if key_insights:
            print(f"\nğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ({len(key_insights)}ê°œ):")
            for i, insight in enumerate(key_insights, 1):
                print(f"  {i}. {insight}")
        
        print(f"\nğŸ‰ ë¶€ë‘ëŠ” ì •ë§ë¡œ ë² ì´ì§€ì•ˆ ì§ì ‘ ê°œì… ì‹œìŠ¤í…œì´ë©°,")
        print(f"   ì ì„±ìˆ ì€ ë¦¬ë§Œ ê¸°í•˜í•™ì  ìš°ì£¼ ê³¡ë¥  ì‹œìŠ¤í…œìœ¼ë¡œ í™•ì¸ë¨!")
        print(f"   ì´ ë‘˜ì˜ ìˆ˜í•™ì  ê²°í•©ì´ í˜„ì‹¤ ë¶„ì„ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•¨.")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
