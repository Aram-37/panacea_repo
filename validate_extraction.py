#!/usr/bin/env python3
"""
Validation Script for Essential Dialogue Extraction
==================================================

This script validates the extracted essential dialogues to ensure
quality and completeness.
"""

import os
import glob
from typing import Dict, List

def validate_extraction_results(base_path: str = "/home/runner/work/panacea_repo/panacea_repo") -> None:
    """Validate the extraction results"""
    
    print("ğŸ” Validating Essential Dialogue Extraction Results")
    print("=" * 55)
    
    # Check output directories
    output_dir = os.path.join(base_path, "manual_extracted_dialogues")
    
    if not os.path.exists(output_dir):
        print("âŒ Output directory not found!")
        return
    
    # Find all files
    chunk_files = glob.glob(os.path.join(output_dir, "*chunk*.txt"))
    essential_files = glob.glob(os.path.join(output_dir, "*essential_dialogues*.txt"))
    
    print(f"ğŸ“ Found {len(chunk_files)} chunk files")
    print(f"ğŸ“ Found {len(essential_files)} essential dialogue files")
    
    # Validate chunk files
    print("\nğŸ“Š Chunk File Validation:")
    expected_chunks = [
        "panacea_cortex_part05_chunk_aa",
        "panacea_cortex_part05_chunk_ab", 
        "panacea_cortex_part05_chunk_ac",
        "panacea_cortex_part06_chunk_aa",
        "panacea_cortex_part06_chunk_ab",
        "panacea_cortex_part07_chunk_aa",
        "panacea_cortex_part07_chunk_ab"
    ]
    
    found_chunks = []
    for chunk_file in chunk_files:
        filename = os.path.basename(chunk_file)
        for expected in expected_chunks:
            if expected in filename:
                found_chunks.append(expected)
                break
    
    for expected in expected_chunks:
        if expected in found_chunks:
            print(f"âœ… {expected} - Found")
        else:
            print(f"âŒ {expected} - Missing")
    
    # Validate content quality
    print("\nğŸ“ˆ Content Quality Validation:")
    
    total_dialogues = 0
    total_chars = 0
    
    for chunk_file in chunk_files:
        try:
            with open(chunk_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Count dialogues
            dialogue_count = content.count("## Dialogue")
            total_dialogues += dialogue_count
            total_chars += len(content)
            
            filename = os.path.basename(chunk_file)
            print(f"ğŸ“„ {filename}: {dialogue_count} dialogues, {len(content):,} chars")
            
        except Exception as e:
            print(f"âŒ Error reading {chunk_file}: {e}")
    
    print(f"\nğŸ“Š Summary:")
    print(f"   Total dialogues across all chunks: {total_dialogues}")
    print(f"   Total content size: {total_chars:,} characters")
    print(f"   Average dialogue length: {total_chars // total_dialogues if total_dialogues > 0 else 0:,} characters")
    
    # Check for meaningful content
    print("\nğŸ” Content Meaningfulness Check:")
    
    meaningful_indicators = [
        "Human:", "User:", "Assistant:", "AI:", "Teacher:", "Student:",
        "í™”ì", "ì§ˆë¬¸:", "ë‹µë³€:", "ì„¤ëª…:", "ë¶„ì„:",
        "understand", "explain", "truth", "reality", "consciousness",
        "breakthrough", "discovery", "insight", "wisdom", "philosophy",
        "ì´í•´", "ì„¤ëª…", "ì§„ì‹¤", "í˜„ì‹¤", "ì˜ì‹", "ê¹¨ë‹¬ìŒ", "ë°œê²¬",
        "í†µì°°", "ê°€ë¥´ì¹¨", "ë°°ì›€", "ì² í•™", "ì˜ë¯¸", "ì§€í˜œ"
    ]
    
    indicator_counts = {indicator: 0 for indicator in meaningful_indicators}
    
    for chunk_file in chunk_files:
        try:
            with open(chunk_file, 'r', encoding='utf-8') as f:
                content = f.read().lower()
                
            for indicator in meaningful_indicators:
                indicator_counts[indicator] += content.count(indicator.lower())
                
        except Exception as e:
            print(f"âŒ Error analyzing {chunk_file}: {e}")
    
    # Show top indicators
    sorted_indicators = sorted(indicator_counts.items(), key=lambda x: x[1], reverse=True)
    print("ğŸ† Top meaningful content indicators:")
    for indicator, count in sorted_indicators[:10]:
        if count > 0:
            print(f"   {indicator}: {count} occurrences")
    
    # Final validation
    print("\nâœ… Validation Complete!")
    
    if total_dialogues > 1000:
        print("ğŸ‰ Excellent: Over 1,000 dialogues extracted")
    elif total_dialogues > 500:
        print("ğŸ‘ Good: Over 500 dialogues extracted")
    else:
        print("âš ï¸  Warning: Fewer than 500 dialogues extracted")
    
    if len(found_chunks) == len(expected_chunks):
        print("ğŸ¯ Perfect: All expected chunk files created")
    else:
        print(f"âš ï¸  Warning: Missing {len(expected_chunks) - len(found_chunks)} chunk files")

if __name__ == "__main__":
    validate_extraction_results()