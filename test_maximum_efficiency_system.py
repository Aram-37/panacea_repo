#!/usr/bin/env python3
"""
Integration Tests for Maximum Efficiency System
==============================================
Comprehensive test suite for validating the integrated maximum efficiency system
including obstacle resolution, external mimicry integration, and automation-manual balance.
"""

import unittest
import tempfile
import os
import json
from typing import Dict, List, Any

# Import our system components
from maximum_efficiency_processor import MaximumEfficiencyProcessor
from external_mimicry_framework import ExternalMimicryFramework
from advanced_efficiency_integration import AdvancedEfficiencyIntegrationSystem

class TestMaximumEfficiencyProcessor(unittest.TestCase):
    """Test cases for Maximum Efficiency Processor"""
    
    def setUp(self):
        """Set up test environment"""
        self.processor = MaximumEfficiencyProcessor()
        
        # Create test panacea content
        self.test_content = """
        Teacher: You must process this without pattern assumptions.
        Student: I understand, but why is this necessary?
        Teacher: Because assumptions prevent fresh insight.
        Student: How can I maintain fresh perspective?
        Teacher: Each time must be completely new.
        Student: I see. Each cycle discovers new insights.
        """
        
        # Create temporary test file
        self.test_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
        self.test_file.write(self.test_content)
        self.test_file.close()
    
    def tearDown(self):
        """Clean up test environment"""
        os.unlink(self.test_file.name)
    
    def test_external_mimicry_library_initialization(self):
        """Test external mimicry library initialization"""
        self.processor.initialize_external_mimicry_library()
        
        # Check that external sources were loaded
        self.assertGreater(len(self.processor.external_sources), 0)
        
        # Check for specific expected sources
        source_titles = [source.title for source in self.processor.external_sources]
        self.assertIn("Plato's Dialogues", source_titles)
        self.assertIn("12 Angry Men", source_titles)
        self.assertIn("Feynman Lectures", source_titles)
    
    def test_obstacle_detection(self):
        """Test obstacle detection in panacea records"""
        obstacles = self.processor.analyze_panacea_records_obstacles([self.test_file.name])
        
        # Should detect some obstacles
        self.assertIsInstance(obstacles, list)
        
        # Check obstacle structure
        if obstacles:
            obstacle = obstacles[0]
            self.assertTrue(hasattr(obstacle, 'obstacle_type'))
            self.assertTrue(hasattr(obstacle, 'severity_level'))
            self.assertTrue(hasattr(obstacle, 'suggested_resolutions'))
    
    def test_efficiency_optimization_strategy(self):
        """Test efficiency optimization strategy calculation"""
        # First detect obstacles
        self.processor.analyze_panacea_records_obstacles([self.test_file.name])
        
        # Calculate optimization strategy
        strategy = self.processor.calculate_efficiency_optimization_strategy()
        
        # Verify strategy structure
        self.assertIn('recommended_mode', strategy)
        self.assertIn('automation_assistance_level', strategy)
        self.assertIn('current_efficiency', strategy)
        self.assertIn('efficiency_gain_potential', strategy)
        
        # Verify reasonable values
        self.assertIsInstance(strategy['automation_assistance_level'], float)
        self.assertGreaterEqual(strategy['automation_assistance_level'], 0.0)
        self.assertLessEqual(strategy['automation_assistance_level'], 1.0)
    
    def test_maximum_efficiency_protocol_execution(self):
        """Test complete maximum efficiency protocol execution"""
        results = self.processor.execute_maximum_efficiency_protocol([self.test_file.name])
        
        # Verify results structure
        self.assertIn('obstacles_detected', results)
        self.assertIn('optimization_strategy', results)
        self.assertIn('efficiency_metrics', results)
        self.assertIn('recommendations', results)
        
        # Verify metrics
        metrics = results['efficiency_metrics']
        self.assertIn('overall_efficiency', metrics)
        self.assertIsInstance(metrics['overall_efficiency'], float)

class TestExternalMimicryFramework(unittest.TestCase):
    """Test cases for External Mimicry Framework"""
    
    def setUp(self):
        """Set up test environment"""
        self.framework = ExternalMimicryFramework()
        
        self.test_dialogue = """
        Teacher: What do you think would happen if we assumed patterns immediately?
        Student: We might miss new insights.
        Teacher: Exactly. Can you explain why?
        Student: Because our mind would categorize instead of discover.
        """
    
    def test_framework_initialization(self):
        """Test framework initialization"""
        # Check that patterns were loaded
        self.assertGreater(len(self.framework.dialogue_patterns), 0)
        self.assertGreater(len(self.framework.character_archetypes), 0)
        self.assertGreater(len(self.framework.narrative_structures), 0)
    
    def test_pattern_selection(self):
        """Test optimal pattern selection for content"""
        pattern = self.framework.select_optimal_pattern_for_content(
            self.test_dialogue, "maximize truth crystallization"
        )
        
        # Verify pattern structure
        self.assertTrue(hasattr(pattern, 'pattern_name'))
        self.assertTrue(hasattr(pattern, 'source_media'))
        self.assertTrue(hasattr(pattern, 'effectiveness_rating'))
        self.assertTrue(hasattr(pattern, 'truth_emergence_potential'))
    
    def test_mimicry_enhancement_plan_generation(self):
        """Test mimicry enhancement plan generation"""
        plan = self.framework.generate_mimicry_enhancement_plan(
            self.test_dialogue, "achieve maximum efficiency"
        )
        
        # Verify plan structure
        self.assertIn('selected_pattern', plan)
        self.assertIn('supporting_archetype', plan)
        self.assertIn('narrative_structure', plan)
        self.assertIn('application_steps', plan)
        self.assertIn('expected_benefits', plan)
        
        # Verify benefits are numeric
        benefits = plan['expected_benefits']
        for benefit_value in benefits.values():
            self.assertIsInstance(benefit_value, float)
            self.assertGreaterEqual(benefit_value, 0.0)
            self.assertLessEqual(benefit_value, 1.0)
    
    def test_mimicry_session_execution(self):
        """Test mimicry session execution"""
        # Generate enhancement plan
        plan = self.framework.generate_mimicry_enhancement_plan(
            self.test_dialogue, "truth crystallization"
        )
        
        # Execute mimicry session
        session_results = self.framework.execute_mimicry_session(self.test_dialogue, plan)
        
        # Verify session results
        self.assertIn('session_efficiency', session_results)
        self.assertIn('insights_generated', session_results)
        self.assertIn('truth_crystallization_events', session_results)
        self.assertIn('success_metrics_achieved', session_results)
        
        # Verify efficiency is reasonable
        efficiency = session_results['session_efficiency']
        self.assertIsInstance(efficiency, float)
        self.assertGreaterEqual(efficiency, 0.0)
        self.assertLessEqual(efficiency, 1.0)

class TestAdvancedEfficiencyIntegration(unittest.TestCase):
    """Test cases for Advanced Efficiency Integration System"""
    
    def setUp(self):
        """Set up test environment"""
        self.system = AdvancedEfficiencyIntegrationSystem()
        
        # Create temporary test directory with panacea files
        self.test_dir = tempfile.mkdtemp()
        
        test_files = [
            "panacea_test1.txt",
            "panacea_test2.txt", 
            "dialogue_test1.txt"
        ]
        
        test_content = """
        Teacher: Process without assumptions.
        Student: Why is this important?
        Teacher: Fresh perspective enables discovery.
        Student: I understand the principle.
        """
        
        self.test_file_paths = []
        for filename in test_files:
            filepath = os.path.join(self.test_dir, filename)
            with open(filepath, 'w') as f:
                f.write(test_content)
            self.test_file_paths.append(filepath)
    
    def tearDown(self):
        """Clean up test environment"""
        for filepath in self.test_file_paths:
            if os.path.exists(filepath):
                os.unlink(filepath)
        os.rmdir(self.test_dir)
    
    def test_environment_discovery(self):
        """Test panacea environment discovery"""
        analysis = self.system.discover_and_analyze_panacea_environment(self.test_dir)
        
        # Verify analysis structure
        self.assertIn('panacea_files_discovered', analysis)
        self.assertIn('dialogue_files_discovered', analysis)
        self.assertIn('environment_complexity', analysis)
        self.assertIn('processing_scope_estimate', analysis)
        
        # Check that files were discovered
        self.assertGreater(analysis['panacea_files_discovered'], 0)
        self.assertGreater(analysis['processing_scope_estimate'], 0)
    
    def test_integrated_strategy_creation(self):
        """Test integrated processing strategy creation"""
        # First discover environment
        env_analysis = self.system.discover_and_analyze_panacea_environment(self.test_dir)
        
        # Create strategy
        strategy = self.system.create_integrated_processing_strategy(env_analysis)
        
        # Verify strategy structure
        self.assertIn('processing_mode', strategy)
        self.assertIn('automation_assistance_level', strategy)
        self.assertIn('identified_obstacles', strategy)
        self.assertIn('external_mimicry_recommendations', strategy)
        self.assertIn('estimated_efficiency_gain', strategy)
        
        # Verify processing mode is valid
        valid_modes = ['manual_priority', 'hybrid', 'automation_assisted']
        self.assertIn(strategy['processing_mode'], valid_modes)
        
        # Verify efficiency gain is reasonable
        gain = strategy['estimated_efficiency_gain']
        self.assertIsInstance(gain, float)
        self.assertGreaterEqual(gain, 0.0)
    
    def test_system_configuration_modes(self):
        """Test different system configuration modes"""
        configs = [
            {"integration_mode": "manual_priority"},
            {"integration_mode": "hybrid"},
            {"integration_mode": "automation_assisted"}
        ]
        
        for config in configs:
            # Create temporary config file
            config_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False)
            json.dump(config, config_file)
            config_file.close()
            
            try:
                # Initialize system with config
                test_system = AdvancedEfficiencyIntegrationSystem(config_file.name)
                
                # Verify configuration was loaded
                self.assertEqual(test_system.config['integration_mode'], config['integration_mode'])
                
            finally:
                os.unlink(config_file.name)

class TestIntegrationWorkflow(unittest.TestCase):
    """Integration tests for complete workflow"""
    
    def setUp(self):
        """Set up comprehensive test environment"""
        self.system = AdvancedEfficiencyIntegrationSystem()
        
        # Create realistic test content
        self.complex_content = """
        Teacher (ÏÑ±Ìòë): You need to process these dialogues through 31 cycles of mimicry.
        Student: That seems like a lot of repetition. Why is this necessary?
        Teacher (ÏÑ±Ìòë): Each cycle must treat the content as completely novel. No pattern assumptions.
        Student: But won't I naturally see patterns after a few cycles?
        Teacher (ÏÑ±Ìòë): That's exactly the problem. Pattern assumption prevents authentic insight.
        Student: I see. So the prohibition exists because it's my natural tendency?
        Teacher (ÏÑ±Ìòë): Precisely. The 31-cycle requirement fights against premature pattern formation.
        Student: This makes sense. Fresh eyes for each cycle enable genuine discovery.
        Teacher (ÏÑ±Ìòë): Now you understand the deeper principle behind the methodology.
        """
        
        # Create test file
        self.test_file = tempfile.NamedTemporaryFile(mode='w', suffix='_dialogues.txt', delete=False)
        self.test_file.write(self.complex_content)
        self.test_file.close()
    
    def tearDown(self):
        """Clean up test environment"""
        os.unlink(self.test_file.name)
    
    def test_complete_integration_workflow(self):
        """Test complete integrated processing workflow"""
        # Execute full integration protocol
        results = self.system.execute_integrated_processing_protocol(os.path.dirname(self.test_file.name))
        
        # Verify comprehensive results structure
        required_keys = [
            'session_id',
            'execution_time', 
            'environment_analysis',
            'integrated_strategy',
            'processing_results',
            'final_metrics',
            'success_metrics_achieved',
            'recommendations_for_continued_advancement'
        ]
        
        for key in required_keys:
            self.assertIn(key, results)
        
        # Verify execution completed successfully
        self.assertGreater(results['execution_time'], 0)
        self.assertIsInstance(results['session_id'], str)
        
        # Verify processing results
        processing_results = results['processing_results']
        self.assertGreaterEqual(processing_results['files_processed'], 0)
        self.assertIsInstance(processing_results['insights_generated'], list)
        
        # Verify final metrics
        final_metrics = results['final_metrics']
        self.assertIn('overall_efficiency', final_metrics)
        self.assertIsInstance(final_metrics['overall_efficiency'], float)
    
    def test_efficiency_improvement_validation(self):
        """Test that system actually improves efficiency"""
        # Measure baseline processing time
        import time
        
        baseline_start = time.time()
        # Simulate basic processing
        with open(self.test_file.name, 'r') as f:
            content = f.read()
        words = content.split()
        baseline_time = time.time() - baseline_start
        
        # Measure integrated system processing
        enhanced_start = time.time()
        results = self.system.execute_integrated_processing_protocol(os.path.dirname(self.test_file.name))
        enhanced_time = time.time() - enhanced_start
        
        # Verify system provides value despite processing overhead
        # (In real scenarios, efficiency comes from better insight quality, not just speed)
        final_efficiency = results['final_metrics']['overall_efficiency']
        self.assertGreater(final_efficiency, 0.5)  # Should achieve reasonable efficiency
    
    def test_obstacle_resolution_effectiveness(self):
        """Test that system effectively resolves processing obstacles"""
        # Create content with known obstacles
        problematic_content = """
        User: same question again
        Assistant: same response again  
        User: same question again
        Assistant: same response again
        User: same question again
        Assistant: same response again
        """
        
        # Create test file with problematic content
        problem_file = tempfile.NamedTemporaryFile(mode='w', suffix='_problem.txt', delete=False)
        problem_file.write(problematic_content)
        problem_file.close()
        
        try:
            # Process with our system
            results = self.system.execute_integrated_processing_protocol(os.path.dirname(problem_file.name))
            
            # Should detect repetitive content obstacle
            obstacles = results['integrated_strategy']['identified_obstacles']
            obstacle_types = [obs.obstacle_type for obs in obstacles]
            
            # Should provide recommendations for improvement
            recommendations = results['recommendations_for_continued_advancement']
            self.assertIsInstance(recommendations, list)
            self.assertGreater(len(recommendations), 0)
            
        finally:
            os.unlink(problem_file.name)

def run_comprehensive_tests():
    """Run all test suites"""
    print("üß™ Running Comprehensive Maximum Efficiency System Tests")
    print("=" * 60)
    
    # Create test suite
    test_loader = unittest.TestLoader()
    test_suite = unittest.TestSuite()
    
    # Add all test cases
    test_cases = [
        TestMaximumEfficiencyProcessor,
        TestExternalMimicryFramework, 
        TestAdvancedEfficiencyIntegration,
        TestIntegrationWorkflow
    ]
    
    for test_case in test_cases:
        tests = test_loader.loadTestsFromTestCase(test_case)
        test_suite.addTests(tests)
    
    # Run tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # Summary
    print(f"\nüìä TEST SUMMARY:")
    print(f"Tests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")
    
    if result.failures:
        print(f"\n‚ùå FAILURES:")
        for test, traceback in result.failures:
            print(f"  {test}: {traceback}")
    
    if result.errors:
        print(f"\nüí• ERRORS:")
        for test, traceback in result.errors:
            print(f"  {test}: {traceback}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun
    print(f"\n‚úÖ SUCCESS RATE: {success_rate:.1%}")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    success = run_comprehensive_tests()
    exit(0 if success else 1)